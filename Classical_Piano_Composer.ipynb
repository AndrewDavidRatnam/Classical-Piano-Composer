{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CHECKING SYSTEM HARDWARE AND IMPORTS"
      ],
      "metadata": {
        "id": "ZrCDt0h92q-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi3EqecrlIRu",
        "outputId": "3b3de7c1-d9b3-40e4-ee18-3259bf7b3589"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwIhU3iozcQe",
        "outputId": "a6a7941c-1755-4cf8-93c7-9d8c41d97c7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU WHOOHOO\n",
            "Device name: /physical_device:CPU:0\n",
            "Device name: /physical_device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if not (tf.config.list_physical_devices('TPU') or tf.config.list_physical_devices('GPU') ):\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
        "              \"accelerator.\")\n",
        "    if \"kaggle_secrets\" in sys.modules:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "elif tf.config.list_physical_devices(\"TPU\"):\n",
        "  print(\"LEZZZZZZ GOOOO  TPU\") #ALL GOOD\n",
        "else:\n",
        "  print(\"Using GPU WHOOHOO\")\n",
        "physical_devices = tf.config.list_physical_devices()\n",
        "for device in physical_devices:\n",
        "    print(\"Device name:\", device.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports for the Project"
      ],
      "metadata": {
        "id": "OZfShAzR3peh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pickle\n",
        "from music21 import converter, instrument, note, chord"
      ],
      "metadata": {
        "id": "rlmRknoQ3Az7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GET NOTES AND CHORDS FROM THE MIDI FILES"
      ],
      "metadata": {
        "id": "dSA0e4nj39Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes():\n",
        "\n",
        "  notes = []\n",
        "\n",
        "  for midi_file in glob.glob(\"/content/drive/MyDrive/midi_songs/*.mid\"): # all .mid files in midi_songs\n",
        "    midi = converter.parse(midi_file) #WHAT DOES THIS DO EXCATLY?\n",
        "\n",
        "    print(\"Parsing %s\" % midi_file)\n",
        "\n",
        "    notes_to_parse = None\n",
        "\n",
        "    try:\n",
        "      s2 = instrument.partitionByInstrument(midi)\n",
        "      notes_to_parse = s2.parts[0].recurse() # WHAT DOES THIS DO EXACTLY?\n",
        "    except:\n",
        "      notes_to_parse = midi.flat.notes # file has notes in a flat structure\n",
        "\n",
        "    for element in notes_to_parse:\n",
        "      if isinstance(element, note.Note):\n",
        "        notes.append(str(element.pitch))\n",
        "      elif isinstance(element, chord.Chord):\n",
        "        notes.append(\".\".join(str(n) for n in element.normalOrder)) # Since only piano composer it is only chords and notes\n",
        "        \"\"\"\n",
        "        1. here when song ends and another song begins it hinders generation, example ending in pianisomo will affect the start of next song\n",
        "        2. need all songs of same nature ie counts/beats, same genre else bias training when ending one song will impact generation of next song\n",
        "         so something like zero padding in convnets to make all songs of same length and then convert to original length\n",
        "        \"\"\"\n",
        "    \"\"\"\n",
        "    See how other midi files in hip hop and pop and clssical and metal and rock have different music21.(\"notes\", \"chords\", \"stuff etc\")\n",
        "    \"\"\"\n",
        "\n",
        "  # with open('notes', 'wb') as filepath:\n",
        "  #   pickle.dump(notes, filepath) # when saving notes already saved and preprocessed so just use that\n",
        "\n",
        "  return notes\n",
        "\n"
      ],
      "metadata": {
        "id": "VxJmOBvi4G0i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I haven't even understood the data to design a input/output sequence will come back to this later"
      ],
      "metadata": {
        "id": "yCF1c8BiBYcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the input/output sequence\n",
        "input is sequence, output is a character or note"
      ],
      "metadata": {
        "id": "HdjA5u6hJyyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, n_vocab, sequence_length=100):#tune this hyper parameter\n",
        "  \"\"\"\n",
        "  Prepare the sequences used by the Neural Network\n",
        "  #FUTURE IMPROVEMENTS\n",
        "  Try to set this hyper parameter correctly use domain knowledge or supervised pretrainning\n",
        "    1. Domain Knowledge, pair up similar songs with similar tempos and verse length so that it easily learn that specific catefory\n",
        "    2. unsupervised does essentially the same thing and trains differnt models/networks for each and first classifies or validates input\n",
        "      from user for type of song and then does music generation\n",
        "  \"\"\"\n",
        "\n",
        "  # get all pitch names\n",
        "  pitchnames = sorted(set( item for item in notes))\n",
        "\n",
        "  #create a dictionary to map pitches to integers\n",
        "  note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "  network_input = []\n",
        "  network_output = []\n",
        "\n",
        "  #create input sequences and the corresponding outputs\n",
        "  for i in range (0, len(notes) - sequence_length, 1):\n",
        "    sequence_in = notes[i:i + sequence_length] #this is input sequence\n",
        "    sequence_out = notes[i+sequence_length] #generating note instead of sequence\n",
        "    network_input.append([note_to_int[char] for char in sequence_in]) # creates a list of input sequence (notes->integers)\n",
        "    network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "  n_patterns = len(network_input) # no of input patterns\n",
        "\n",
        "  #EVERYONE HATES INPUT SHAPE ERROR LOL\n",
        "  network_input = np.reshape(network_input, (n_patterns,sequence_length, 1))\n",
        "\n",
        "  #normalize input , use standard scaler, batch normalization?\n",
        "  # this is standard 0-1 i guess like pixel/255\n",
        "  network_input = network_input / float(n_vocab)\n",
        "\n",
        "  network_output = tf.one_hot(network_output, n_vocab) # one hot encode the output\n",
        "\n",
        "  \"\"\"\n",
        "  one hot encoding a whole vocabulary in NLP is also not widely popular, see and check out some transferable methods instead\n",
        "  of one-hot encoding the whole vocablulary of notes.\n",
        "  In piano it is fine, but when you go all the instruments, beats, and other instruments with violin and everthing in between you need a better\n",
        "  categorical represenetaion.\n",
        "  \"\"\"\n",
        "\n",
        "  return (network_input, network_output)\n"
      ],
      "metadata": {
        "id": "0BCLjxwr8TdU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Network Model/Architecture"
      ],
      "metadata": {
        "id": "TXaZ3beoJwv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(network_input, n_vocab):\n",
        "  model = tf.keras.models.Sequential([\n",
        "      #ADD CONV1D if you can\n",
        "      tf.keras.layers.LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "                          recurrent_dropout=0.3,\n",
        "                          return_sequences=True),\n",
        "      tf.keras.layers.LSTM(511, return_sequences=True, recurrent_dropout=0.3),\n",
        "      tf.keras.layers.LSTM(512),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Dense(n_vocab, activation=\"softmax\")\n",
        "  ])\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "R3ijhOxqKMjj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, network_input, network_output):\n",
        "  filepath = \"weights_improvement--{epoch:02d}-{loss:.4f} - bigger.hdf5\"\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath,\n",
        "      monitor=\"loss\",\n",
        "      verbose=0,\n",
        "      save_best_only=True,\n",
        "      mode=\"min\"\n",
        "  )\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                    restore_best_weights=True)\n",
        "  callbacks_list=[checkpoint, early_stopping]\n",
        "  model.fit(network_input, network_output, epochs=5, batch_size=32, callbacks=callbacks_list)\n",
        ""
      ],
      "metadata": {
        "id": "ezGGMNB-KUaz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DRIVER FUNCTION/CALL"
      ],
      "metadata": {
        "id": "en5-l0mXi6N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def driver_function():\n",
        "  notes = get_notes()\n",
        "\n",
        "  n_vocab = len(set(notes))\n",
        "  network_input, network_output = prepare_sequences(notes, n_vocab) #can also set sequence length as an argument, default = 100\n",
        "\n",
        "  model = create_model(network_input, n_vocab)\n",
        "  train(model, network_input, network_output)\n"
      ],
      "metadata": {
        "id": "zV8M8DRWhjvt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "exec_time = timeit.timeit(driver_function, number=1)\n",
        "print(\"DONE----\"*8)\n",
        "print(exec_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpWEWTz0lq2Y",
        "outputId": "0e352252-9cbf-43f1-cb04-bf725cdb12dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing /content/drive/MyDrive/midi_songs/Eternal_Harvest.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Cids.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FF3_Third_Phase_Final_(Piano).mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/AT.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FF3_Battle_(Piano).mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/BlueStone_LastDungeon.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/DOS.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/EyesOnMePiano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/0fithos.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/8.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Ff4-BattleLust.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Fiend_Battle_(Piano).mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FF4.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FFVII_BATTLE.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Ff7-Jenova_Absolute.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FF8_Shuffle_or_boogie_pc.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Ff7-One_Winged.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Finalfantasy5gilgameshp.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Finalfantasy6fanfarecomplete.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Fierce_Battle_(Piano).mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Ff7-Cinco.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FFIXQuMarshP.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FFIX_Piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FFIII_Edgar_And_Sabin_Piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/FF6epitaph_piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Zelda_Overworld.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Fyw_piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/HighwindTakestotheSkies.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Oppressed.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/JENOVA.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Life_Stream.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ViviinAlexandria.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/VincentPiano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ahead_on_our_way_piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Rydia_pc.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Kingdom_Hearts_Dearly_Beloved.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Gold_Silver_Rival_Battle.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Kingdom_Hearts_Traverse_Town.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Suteki_Da_Ne_(Piano_Version).mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/In_Zanarkand.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Still_Alive-1.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/Rachel_Piano_tempofix.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/OTD5YA.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/decisive.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff4-town.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff6shap.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/caitsith.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/braska.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff4pclov.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff4_piano_collections-main_theme.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/dontbeafraid.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff4-airship.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/bcm.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/dayafter.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff4-fight1.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff1battp.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/balamb.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff11_awakening_piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/cosmo.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/electric_de_chocobo.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/costadsol.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/sandy.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/lurk_in_dark.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/gerudo.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/mining.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/relmstheme-piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff8-lfp.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff7-mainmidi.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/redwings.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/figaro.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/rufus.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/goldsaucer.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ff7themep.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/fortresscondor.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/path_of_repentance.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/pkelite4.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/great_war.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/sera_.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/roseofmay-piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/sobf.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/thoughts.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ultros.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/tpirtsd-piano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/waltz_de_choco.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/z_aeristhemepiano.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/ultimafro.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/traitor.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/tifap.mid\n",
            "Parsing /content/drive/MyDrive/midi_songs/thenightmarebegins.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1434/1434 [==============================] - ETA: 0s - loss: 4.9021"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1434/1434 [==============================] - 857s 589ms/step - loss: 4.9021\n",
            "Epoch 2/5\n",
            "1434/1434 [==============================] - ETA: 0s - loss: 4.6990"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1434/1434 [==============================] - 821s 572ms/step - loss: 4.6990\n",
            "Epoch 3/5\n",
            "1434/1434 [==============================] - ETA: 0s - loss: 4.6924"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1434/1434 [==============================] - 809s 564ms/step - loss: 4.6924\n",
            "Epoch 4/5\n",
            "1434/1434 [==============================] - ETA: 0s - loss: 4.6928"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1434/1434 [==============================] - 815s 569ms/step - loss: 4.6928\n",
            "Epoch 5/5\n",
            "1434/1434 [==============================] - ETA: 0s - loss: 4.6876"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1434/1434 [==============================] - 817s 570ms/step - loss: 4.6876\n",
            "DONE----DONE----DONE----DONE----DONE----DONE----DONE----DONE----\n",
            "4134.900314979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "4134.900314979/60 #minutes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXV1IFNr8CQf",
        "outputId": "3fdaafc1-e29c-471a-ad2b-8cfcccee6d38"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68.91500524965"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to improve:-\n",
        "- use tf data api to get data\n",
        "- build efficient datapipeline\n",
        "- use prefetch and create a tf.data.Dataset\n",
        "- see if you can implement windows\n",
        "-  create val dataset for early stopping\n",
        "-"
      ],
      "metadata": {
        "id": "KF4leH_rmcih"
      }
    }
  ]
}